import base64
import os
from PIL import Image
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage
import google.generativeai as genai
from api_config.prompt import *  # Ensure that this file contains necessary prompt definitions

def image_b64(image):
    """
    Converts an image file to its base64 encoded string.

    Args:
        image (str): Path to the image file.

    Returns:
        str: Base64 encoded string of the image.
    """
    try:
        with open(image, "rb") as f:
            return base64.b64encode(f.read()).decode()
    except Exception as e:
        print(f"Error encoding image to base64: {e}")
        return None

def gen_vision(image_path, prompt):
    """
    Generates a response using the ChatGoogleGenerativeAI model based on a provided image and prompt.

    Args:
        image_path (str): Path to the image file.
        prompt (str): The text prompt to accompany the image.

    Returns:
        str: Response generated by the ChatGoogleGenerativeAI model.
    """
    try:
        # Load environment variables from a .env file
        load_dotenv()

        # Get the Google API key from environment variables
        API_KEY = os.getenv('GOOGLE_API_KEY')
        if not API_KEY:
            raise ValueError("Google API key not found in environment variables")

        # Configure the ChatGoogleGenerativeAI model with the appropriate settings
        genai.configure(api_key=API_KEY)
        max_tokens = 150000
        model = ChatGoogleGenerativeAI(model="gemini-pro", temperature=0.3, max_tokens=max_tokens)

        # Prepare the prompt
        llm = ChatGoogleGenerativeAI(model="gemini-pro-vision")
        message = HumanMessage(
            content=[
                {"type": "text", "text": prompt},  # You can optionally provide text parts
                {"type": "image_url", "image_url": f"data:image/jpeg;base64,{image_path}"},
            ]
        )

        # Invoke the model with the prepared message
        response = llm.invoke([message])
        return response.content

    except Exception as e:
        print(f"An error occurred during vision generation: {e}")
        return None

def gen_vision_for_image(image_url, prompt):
    """
    Generates a response using the ChatGoogleGenerativeAI model based on a provided image and prompt.

    Args:
        image_path (str): Path to the image file.
        prompt (str): The text prompt to accompany the image.

    Returns:
        str: Response generated by the ChatGoogleGenerativeAI model.
    """
    try:
        # Load environment variables from a .env file
        load_dotenv()

        # Get the Google API key from environment variables
        API_KEY = os.getenv('GOOGLE_API_KEY')
        if not API_KEY:
            raise ValueError("Google API key not found in environment variables")

        # Configure the ChatGoogleGenerativeAI model with the appropriate settings
        genai.configure(api_key=API_KEY)
        max_tokens = 150000
        model = ChatGoogleGenerativeAI(model="gemini-pro", temperature=0.3, max_tokens=max_tokens)

        # Prepare the prompt
        llm = ChatGoogleGenerativeAI(model="gemini-pro-vision")
        message = HumanMessage(
            content=[
                {"type": "text", "text": prompt},  # You can optionally provide text parts
                {"type": "image_url", "image_url": image_url},
            ]
        )

        # Invoke the model with the prepared message
        response = llm.invoke([message])
        return response.content

    except Exception as e:
        print(f"An error occurred during vision generation: {e}")
        return None

# Example usage

# b64_image = image_b64('./image_saves/screenshot0.jpg')
# response = gen_vision(b64_image, prompt_image_anylink)
# print(response)
